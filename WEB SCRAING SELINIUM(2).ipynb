{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70a9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter. \n",
    "#You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "#You have to scrape the job-title, job-location, company name, experience required. \n",
    "#The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs \n",
    "#The task will be done as shown in the below steps: \n",
    "#1. first get the web page https://www.naukri.com/\n",
    "#2. Enter “Data Scientist” in “Skill, Designations, and Companies” field. \n",
    "#3. Then click the search button. \n",
    "#4. Then apply the location filter and salary filter by checking the respective boxes \n",
    "#5. Then scrape the data for the first 10 jobs results you get. \n",
    "#6. Finally create a dataframe of the scraped dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105eb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06b2307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b481cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1eecb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "job_title.send_keys(\"Data_Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33aff13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c11a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2419687",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element(By.XPATH,\"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[2]/div[2]/div[1]/label/p/span[1]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd0285bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_data = []\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experiance_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6996ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\" row1\"]')\n",
    "for i in title_tags:\n",
    "    job_title=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ef91cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\" row2\"]')\n",
    "company_name=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a80bab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in title_tags:\n",
    "    location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "178d4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-experience exp\"]')\n",
    "for i in title_tags:\n",
    "    experiance_reqiured=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3aa60ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  jobs_data.append({\n",
    "        'Job Title': job_title,\n",
    "        'Job Location': job_location,\n",
    "        'Company Name': company_name,\n",
    "        'Experience Required': experiance_required\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf891175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Job Title Job Location Company Name Experience Required\n",
      "0        []           []           []                  []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(jobs_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584dac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the \n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58175dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4f695cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "273b05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_title = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "job_title.send_keys(\"Data_Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9927c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, \"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "871ee3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.CLASS_NAME, \"styledcls_body_hidden\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "68c61c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_data = []\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experiance_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c88de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard__jjUmu active white-box-border jobCard\"]')\n",
    "for i in title_tags:\n",
    "    job_title=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c213ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in title_tags:\n",
    "    location=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a15da33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "company_name=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f0a48fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in title_tags:\n",
    "    experiance=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "96182f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "  jobs_data.append({\n",
    "        'Job Title': job_title,\n",
    "        'Job Location': job_location,\n",
    "        'Company Name': company_name,\n",
    "        'Experience Required': experiance_required\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cdc998de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Job Title Job Location   Company Name Experience Required\n",
      "0        []           []  Bangalore\\n+6                  []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(jobs_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=F\n",
    "fLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the stepsrequired during scraping should be done through code only and not manuall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5bc891b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9b832137",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "51604dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_reviews = []\n",
    "ratings = []\n",
    "review_summaries = []\n",
    "full_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2d2e6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rating_element in rating_elements[:100]:\n",
    "    ratings_elements = driver.find_elements(By.XPATH, '//div[@class=\"col._2wzgFH.K0kLPL\"]')\n",
    "    for i in rating_element:\n",
    "        ratings=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "455cf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_summaries in review_summaries[:100]:\n",
    "    reviews_elements= driver.find_elements(By.XPATH,'//div[@class=\"_2-N8zT\"]')\n",
    "    for i in reviews_elements:\n",
    "        reviews=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1869bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_summary in review_summaries[:100]:\n",
    "    review_summaries = driver.find_element(By.XPATH, '//div[@class=\"_2-N8zT\"]')\n",
    "    for i in summaries_elements:\n",
    "          reviews_summaries=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e9ad6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(100, len(ratings), len(review_summaries), len(full_reviews))):\n",
    "    iphone_reviews.append({\n",
    "        'Ratings': ratings[i],\n",
    "        'Review Summary': review_summaries[i],\n",
    "        'Full Review': full_reviews[i]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6f3881c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_reviews = pd.DataFrame({\n",
    "    'Ratings': ratings,\n",
    "    'Review_summary': review_summary,\n",
    "    'Full_Review': full_reviews\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d66da6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Ratings, Review_summary, Full_Review]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(iphone_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecc7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4: Scrape data forfirst 100 sneakers you find whenyouvisitflipkart.com and search for “sneakers” inthe search\n",
    "field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fad1b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c0b3c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cb07de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_elements = driver.find_elements(By.XPATH, \"//input[@type='text']\")\n",
    " search_input.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e7461e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9615672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    brand = sneakers[i].find_element(By.XPATH, \"//div[@class='_2WkVRV\")\n",
    "    brand = brand_element.text\n",
    "    description = sneakers[i].find_element(By.XPATH, \".//a[@class='IRpwTa']\")\n",
    "    description = description_element.text\n",
    "    price = sneakers[i].find_element(By.XPATH, \".//div[@class='_30jeq3 _1_WHN1']\")\n",
    "    price = price_element.text\n",
    "    \n",
    "    data.append({\n",
    "        'Brand': brand.text,\n",
    "        'ProductDescription': description.text,\n",
    "        'Price': price.text\n",
    "    })\n",
    "\n",
    "    if len(data) == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "740c20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers=pd.DataFrame({})\n",
    "sneakers['Brand_name']=B_name[:100]\n",
    "sneakers['P_price']=Price[:100]\n",
    "sneakers['Pr_desc']=P_desc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ccbc95f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>P_price</th>\n",
       "      <th>Pr_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand_name, P_price, Pr_desc]\n",
       "Index: []"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d264c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gitQ5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU\n",
    "Type filter to “Intel Core i7” as shown in the below image\n",
    "Aftersetting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f42ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6817d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_g = driver.find_elements(By.XPATH,\"//input[@type='text']\")\n",
    "search_g.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b659b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_elements(By.XPATH,\"//input[@id='nav-search-submit-button']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb09de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Price=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d07c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    r_desc = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    price = driver.find_elements(By.XPATH\"//div[@class='_25b18c']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e3cb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "  data.append({\n",
    "        'Brand': brand.text,\n",
    "        'Rating': rating.text,\n",
    "        'Price': price.text\n",
    "    })\n",
    "\n",
    "    if len(data) == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuote\n",
    "3. Than scrap a)Quote b) Author c) Type Of Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22f8357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abb595f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quote_button = driver.find_elements(By.CLASS_NAME,'active')\n",
    "top_quote_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02f27c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_text=[]\n",
    "author_name=[] \n",
    "quote_type =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e284b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_quotes:\n",
    "quotes = driver.find_elements(By.XPATH,'//div[@class='/html/body/div[1]/div[2]/div/div/div/div[1]/div/ul/li[1]/div/div[1]']')\n",
    "authors = driver.find_elements(By.PATH,'//div[@class='/html/body/div[1]/div[2]/div/div/div/div[1]/div/ul/li[1]/div/p/a[2]']')\n",
    "types = driver.find_elements(By.XPATH,'//div[@class='/html/body/div[1]/div[2]/div/div/div/div[1]/div/ul/li[1]/div/div[2]/div[1]']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e376400",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append({\n",
    "    'quote text': quote_text\n",
    "    'author name': author_name \n",
    "     'quote type' : quote_type   \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecfd2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Quote: {quote_text}\")\n",
    "    print(f\"Author: {author_name}\")\n",
    "    print(f\"Type of Quote: {quote_type}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53c75672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name,\n",
    "#Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of\u0002all-prime-ministers-of-india-1473165149-1\n",
    "#scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a024d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a528459",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.jagranjosh.com/general-knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d530d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = driver.find_elements(By.XPATH,\"//table[@class='table4']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e475463",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "born_dead = []\n",
    "term_of_office = []\n",
    "remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7ee3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_elements_by_tag_name(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c74d4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_elements_by_tag_name(\"tr\")\n",
    "for row in rows[1:]:  # skipping the header row\n",
    "    columns = row.find_elements_by_tag_name(\"td\")\n",
    "    names.append(columns[0].text.strip())\n",
    "    born_dead.append(columns[1].text.strip())\n",
    "    term_of_office.append(columns[2].text.strip())\n",
    "    remarks.append(columns[3].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6f680ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Born-Dead': born_dead,\n",
    "    'Term of Office': term_of_office,\n",
    "    'Remarks': remarks\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4fce7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8: Write a python program to display list of 50 Most expensive cars in the world\n",
    "#(i.e. Car name and Price) from https://www.motor1.com/\n",
    "#This task will be done in following steps:\n",
    "#1. First get the webpage https://www.motor1.com/\n",
    "#2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "#3. Then click on 50 most expensive carsin the world..\n",
    "#4. Then scrap thementioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98a72c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84f7ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76d117e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_elements(By.CLASS_NAME,\"m1-search-form-button-animate icon-search-svg m1-mobile-search\")\n",
    "search_bar.send_keys(\"50 most expensive cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dc3677c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_elementS(By.xpath,\"/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/button[1]/svg\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d8ea85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_cars_link = driver.find_element(By.XPATH,\"/html/body\")\n",
    "expensive_cars_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a6bcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Car Name\": [\"Car1\", \"Car2\", ...], \"Price\": [\"$100,000\", \"$200,000\", ...]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be19229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Car Name     Price\n",
      "0      Car1  $100,000\n",
      "1      Car2  $200,000\n",
      "2  Ellipsis  Ellipsis\n"
     ]
    }
   ],
   "source": [
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054256a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad19ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
